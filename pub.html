<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<!--- <title>Publications</title> --->
<!-- YOU NEED TO CHANGE THE FOLLOWING LINE WITH YOUR NAME! -->
<title>Dongjie Yu - HKU</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
<meta name="google-site-verification" content="XVEWai_IQg8I-HjBr0M71wsvfCQhvKe7ay7H8kOgjiQ" />
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Dongjie Yu</div>
<div class="menu-item"><a href="index.html">About</a></div>
<div class="menu-item"><a href="pdf/CV_DongjieYu.pdf">CV</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="pub.html" class="current">Publications</a></div>
<div class="menu-item"><a href="proj.html">Projects</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications</h1>
</div>
<p>* means equal contributions.
</p>
<h3>Conference papers</h3>
<ol>
<li><p>[<b>ICML&rsquo;22</b>] <u>Dongjie Yu*</u>, Haitong Ma*, Shengbo Eben Li and Jianyu Chen. &ldquo;Reachability Constrained Reinforcement Learning&rdquo;. <i>Proceedings of the 39th International Conference on Machine Learning</i>, PMLR 162:25636-25655, 2022.
</p>
</li>
</ol>
<dl>
<dt></dt>
<dd><p>tldr: We characterize feasible sets (persistently safe states) with Hamilton-Jacobi reachability analysis in constrained RL. The algorithm reachs a zero-violation policy with competitive performance.
</p></dd>
<dt></dt>
<dd><p><a href="https://proceedings.mlr.press/v162/yu22d.html" target=&ldquo;blank&rdquo;>[Paper]</a> <a href="https://github.com/mahaitongdae/Reachability_Constrained_RL" target=&ldquo;blank&rdquo;>[Code_learning]</a> <a href="https://github.com/ManUtdMoon/safe-control-gym" target=&ldquo;blank&rdquo;>[Code_env]</a>
</p></dd>
</dl>
<h3>Journal papers</h3>
<ol>
<li><p>[<b>T-ASE</b>] <u>Dongjie Yu*</u>, Wenjun Zou, Yujie Yang, Haitong Ma, Shengbo Eben Li, Yuming Yin, Jianyu Chen and Jingliang Duan. &ldquo;Safe Model-Based Reinforcement Learning with an Uncertainty-Aware Reachability Certificate&rdquo;. <i>IEEE Transactions on Automation Science and Engineering</i>, DOI: 10.1109/TASE.2023.3292388, 2023.
</p>
</li>
</ol>
<dl>
<dt></dt>
<dd><p>tldr: We propose a distributional form of reachability certificate to consider the uncertaity of the system dynamics in safe RL. The algorithm is able to learn a zero-violation policy with competitive performance, significantly reducing violations during exploration.
</p></dd>
<dt></dt>
<dd><p><a href="https://arxiv.org/abs/2210.07553" target=&ldquo;blank&rdquo;>[Preprint]</a> <a href="https://github.com/ManUtdMoon/Distributional-Reachability-Policy-Optimization" target=&ldquo;blank&rdquo;>[Code]</a>
</p></dd>
</dl>
<h3>Preprints</h3>
<ol>
<li><p>TBD.
</p>
</li>
</ol>
</td>
</tr>
</table>
</body>
</html>
